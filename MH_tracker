import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Load the datasets
df1 = pd.read_csv('prevalence-by-mental-and-substance-use-disorder.csv')
df2 = pd.read_csv('mental-and-substance-use-as-share-of-disease.csv')

# Merge the datasets
data = pd.merge(df1, df2)
data.drop("Code", axis=1, inplace=True)

# Define a dictionary to map old column names to new shorter column names
column_name_mapping = {
    'Prevalence - Schizophrenia': 'Schizophrenia',
    'Prevalence - Bipolar disorder': 'Bipolar',
    'Prevalence - Eating disorders': 'Eating',
    'Prevalence - Anxiety disorders': 'Anxiety',
    'Prevalence - Drug use disorders': 'Drug_use',
    'Prevalence - Depressive disorders': 'Depressive',
    'Prevalence - Alcohol use disorders': 'Alcohol_use',
}

# Rename the columns using the mapping
data.rename(columns=column_name_mapping, inplace=True)

# Initialize a LabelEncoder
label_encoder = LabelEncoder()

# Convert non-numeric labels into numeric labels
for column in data.select_dtypes(include=['object']).columns:
    data[column] = label_encoder.fit_transform(data[column])

# Split the data into train, validation, and test sets
train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)
valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)

# Prepare the data for modeling
X_train = train_data.drop(columns=['DALY'])
y_train = train_data['DALY']

X_valid = valid_data.drop(columns=['DALY'])
y_valid = valid_data['DALY']

# Best Gradient Boosting model with tuned hyperparameters
best_gb_model = GradientBoostingRegressor(learning_rate=0.2, max_depth=5, n_estimators=300)
best_gb_model.fit(X_train, y_train)

# Make predictions on the validation set
y_valid_pred_gb = best_gb_model.predict(X_valid)

# Calculate various performance metrics
mse_gb = mean_squared_error(y_valid, y_valid_pred_gb)
mae_gb = mean_absolute_error(y_valid, y_valid_pred_gb)
r2_gb = r2_score(y_valid, y_valid_pred_gb)

# Display performance metrics
print(f"Gradient Boosting Mean Squared Error: {mse_gb:.4f}")
print(f"Gradient Boosting Mean Absolute Error: {mae_gb:.4f}")
print(f"Gradient Boosting R-squared: {r2_gb:.4f}")
